{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Q1: Define overfitting and underfitting in machine learning. What are the consequences of each, and how\n",
        "can they be mitigated?"
      ],
      "metadata": {
        "id": "qBGPr40-mbkS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=Overfitting: Occurs when a model learns the training data too well, capturing noise or random fluctuations in the data instead of the underlying patterns. Consequences include poor generalization to unseen data and high variance.\n",
        "\n",
        "=Underfitting: Occurs when a model is too simple to capture the underlying structure of the data, resulting in high bias. Consequences include poor performance on both the training and test datasets."
      ],
      "metadata": {
        "id": "H3HUfZxlmkXu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2: How can we reduce overfitting? Explain in brief."
      ],
      "metadata": {
        "id": "kRKlnEBjmk7z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use simpler models with fewer parameters.\n",
        "Collect more training data to provide the model with a broader range of examples.\n",
        "Apply regularization techniques such as L1/L2 regularization or dropout.\n",
        "Use cross-validation to evaluate model performance and tune hyperparameters.\n",
        "Apply early stopping to halt the training process when the performance on the validation set starts to degrade"
      ],
      "metadata": {
        "id": "mPRSNmUUmuYW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3: Explain underfitting. List scenarios where underfitting can occur in ML."
      ],
      "metadata": {
        "id": "Msw3Rdkgm0bq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=Underfitting occurs when a model is too simple to capture the underlying structure of the data, resulting in poor performance on both the training and test datasets.\n",
        "\n",
        "=Scenarios where underfitting can occur include using a linear model to capture nonlinear relationships in the data, insufficient model complexity for the task at hand, or limited training data."
      ],
      "metadata": {
        "id": "CgigRzKom4C-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4: Explain the bias-variance tradeoff in machine learning. What is the relationship between bias and\n",
        "variance, and how do they affect model performance?"
      ],
      "metadata": {
        "id": "jm6lY3LSm9Kh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=The bias-variance tradeoff refers to the balance between bias (error due to overly simplistic assumptions) and variance (error due to sensitivity to fluctuations in the training data) in machine learning models.\n",
        "\n",
        "=High bias models have low variance but may underfit the data, while high variance models have low bias but may overfit the data.\n",
        "\n",
        "=To achieve optimal model performance, it is essential to strike a balance between bias and variance."
      ],
      "metadata": {
        "id": "DjekLzH6nAWd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q5: Discuss some common methods for detecting overfitting and underfitting in machine learning models.\n",
        "How can you determine whether your model is overfitting or underfitting?"
      ],
      "metadata": {
        "id": "JpSaCB8bnH82"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=Overfitting: Monitor the model's performance on the training and validation datasets. Look for signs of a large gap between training and validation performance. Use techniques like learning curves or validation curves.\n",
        "\n",
        "=Underfitting: Evaluate the model's performance on both the training and test datasets. If the performance is consistently poor on both datasets, it indicates underfitting."
      ],
      "metadata": {
        "id": "44DRGJCtnMdo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q6: Compare and contrast bias and variance in machine learning. What are some examples of high bias\n",
        "and high variance models, and how do they differ in terms of their performance?"
      ],
      "metadata": {
        "id": "lQTNCfP5nUWd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=Bias: Represents the error due to overly simplistic assumptions in the model. High bias models tend to underfit the data.\n",
        "\n",
        "=Variance: Represents the error due to sensitivity to fluctuations in the training data. High variance models tend to overfit the data."
      ],
      "metadata": {
        "id": "AXg1NfzknXog"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q7: What is regularization in machine learning, and how can it be used to prevent overfitting? Describe\n",
        "some common regularization techniques and how they work."
      ],
      "metadata": {
        "id": "4eOLqegsncdo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "=Regularization is a technique used to prevent overfitting by adding a penalty term to the loss function, which discourages overly complex models.\n",
        "\n",
        "=Common regularization techniques include L1 regularization (Lasso), L2 regularization (Ridge), and dropout.\n",
        "\n",
        "=L1 regularization adds the absolute values of the model's coefficients to the loss function, while L2 regularization adds the squared values."
      ],
      "metadata": {
        "id": "JcQYV12YnfjW"
      }
    }
  ]
}